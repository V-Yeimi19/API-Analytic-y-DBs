# API AnalÃ­tica Primac - Microservicio de Data Science

API de anÃ¡lisis de datos para el sistema de seguros Primac que integra informaciÃ³n de 3 microservicios mediante ingesta de datos a S3 y consultas con AWS Athena.

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
- [Arquitectura del Sistema](#-arquitectura-del-sistema)
- [TecnologÃ­as Utilizadas](#-tecnologÃ­as-utilizadas)
- [Requisitos Previos](#-requisitos-previos)
- [InstalaciÃ³n y ConfiguraciÃ³n](#-instalaciÃ³n-y-configuraciÃ³n)
- [Modo Desarrollo Local](#-modo-desarrollo-local)
- [Modo ProducciÃ³n](#-modo-producciÃ³n)
- [Endpoints de la API](#-endpoints-de-la-api)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Troubleshooting](#-troubleshooting)

---

## ğŸ¯ DescripciÃ³n del Proyecto

Este microservicio es parte de un sistema distribuido de seguros donde cada miembro del equipo gestiona un microservicio con su propia base de datos. El microservicio analÃ­tico:

1. **Ingesta datos** del 100% de registros de 3 bases de datos (estrategia pull)
2. **Almacena** los datos en formato CSV en Amazon S3
3. **Cataloga** automÃ¡ticamente los datos en AWS Glue
4. **Ejecuta queries analÃ­ticas** mediante AWS Athena
5. **Expone** resultados a travÃ©s de una API REST documentada con Swagger

### Bases de Datos Integradas:

- **MySQL**: GestiÃ³n de usuarios, clientes, agentes y beneficiarios
- **PostgreSQL**: GestiÃ³n de productos, pÃ³lizas y coberturas
- **Cassandra**: Registro de reclamos, pagos y auditorÃ­a de transacciones

---

## ğŸ—ï¸ Arquitectura del Sistema

### Arquitectura Completa del Equipo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Microservicio 1     â”‚   â”‚  Microservicio 2     â”‚   â”‚  Microservicio 3     â”‚
â”‚  (MySQL)             â”‚   â”‚  (PostgreSQL)        â”‚   â”‚  (Cassandra)         â”‚
â”‚                      â”‚   â”‚                      â”‚   â”‚                      â”‚
â”‚  â€¢ API REST          â”‚   â”‚  â€¢ API REST          â”‚   â”‚  â€¢ API REST          â”‚
â”‚  â€¢ BD MySQL          â”‚   â”‚  â€¢ BD PostgreSQL     â”‚   â”‚  â€¢ BD Cassandra      â”‚
â”‚  â€¢ CompaÃ±ero A       â”‚   â”‚  â€¢ CompaÃ±ero B       â”‚   â”‚  â€¢ CompaÃ±ero C       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                          â”‚                          â”‚
           â”‚                          â”‚                          â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                         ConexiÃ³n a bases de datos remotas
                                      â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚                         â”‚
                         â”‚  TU MICROSERVICIO       â”‚
                         â”‚  ANALÃTICO              â”‚
                         â”‚                         â”‚
                         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                         â”‚  â”‚ 1. INGESTA       â”‚   â”‚
                         â”‚  â”‚  â€¢ Pull 100% BD  â”‚   â”‚
                         â”‚  â”‚  â€¢ Export CSV    â”‚   â”‚
                         â”‚  â”‚  â€¢ Upload S3     â”‚   â”‚
                         â”‚  â”‚  â€¢ Catalog Glue  â”‚   â”‚
                         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                         â”‚           â”‚             â”‚
                         â”‚           â–¼             â”‚
                         â”‚     Amazon S3           â”‚
                         â”‚     AWS Glue            â”‚
                         â”‚           â”‚             â”‚
                         â”‚           â–¼             â”‚
                         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                         â”‚  â”‚ 2. API ANALÃTICA â”‚   â”‚
                         â”‚  â”‚  â€¢ FastAPI       â”‚   â”‚
                         â”‚  â”‚  â€¢ Pandas        â”‚   â”‚
                         â”‚  â”‚  â€¢ Queries S3    â”‚   â”‚
                         â”‚  â”‚  â€¢ Swagger UI    â”‚   â”‚
                         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                         â”‚           â”‚             â”‚
                         â”‚           â–¼             â”‚
                         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
                         â”‚  â”‚ 3. LOAD BALANCER â”‚   â”‚
                         â”‚  â”‚  â€¢ Nginx         â”‚   â”‚
                         â”‚  â”‚  â€¢ 2 VMs Prod    â”‚   â”‚
                         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                         â”‚                         â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos

```
1. INGESTA (Una sola vez)
   MySQL/PostgreSQL/Cassandra â†’ Contenedor Ingesta â†’ S3 â†’ AWS Glue Catalog

2. CONSULTAS (Continuas)
   Usuario â†’ Nginx â†’ API AnalÃ­tica â†’ Lee S3 â†’ Procesa con Pandas â†’ Retorna JSON
```

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Backend
- **Python 3.11**: Lenguaje principal
- **FastAPI**: Framework web para API REST
- **Uvicorn**: Servidor ASGI
- **Pandas**: Procesamiento y anÃ¡lisis de datos
- **Boto3**: SDK de AWS para Python

### Bases de Datos
- **MySQL 8.0**: Base de datos relacional
- **PostgreSQL 16**: Base de datos relacional avanzada
- **Cassandra 4.1**: Base de datos NoSQL distribuida

### Conectores de Bases de Datos
- **PyMySQL**: Conector MySQL
- **Psycopg2**: Conector PostgreSQL
- **Cassandra Driver**: Conector Cassandra

### AWS Services
- **Amazon S3**: Almacenamiento de datos
- **AWS Glue**: CatÃ¡logo de datos
- **AWS Athena**: Queries SQL sobre S3 (preparado para uso)

### DevOps
- **Docker**: ContenedorizaciÃ³n
- **Docker Compose**: OrquestaciÃ³n de contenedores
- **Nginx**: Balanceador de carga
- **Git**: Control de versiones

---

## ğŸ“¦ Requisitos Previos

### Software Necesario

- **Docker** (versiÃ³n 20.10+)
- **Docker Compose** (versiÃ³n 2.0+)
- **Git**
- **Cuenta AWS** con permisos para S3 y Glue

### Permisos IAM Requeridos en AWS

Tu usuario IAM debe tener los siguientes permisos:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::tu-bucket-name",
        "arn:aws:s3:::tu-bucket-name/*"
      ]
    },
    {
      "Effect": "Allow",
      "Action": [
        "glue:CreateDatabase",
        "glue:GetDatabase",
        "glue:CreateTable",
        "glue:UpdateTable",
        "glue:GetTable"
      ],
      "Resource": "*"
    }
  ]
}
```

### InformaciÃ³n Requerida de CompaÃ±eros (Solo para ProducciÃ³n)

Para desplegar en producciÃ³n, necesitas que tus compaÃ±eros te proporcionen:

**CompaÃ±ero con MySQL:**
- Host/IP de la base de datos
- Puerto (usualmente 3306)
- Usuario y contraseÃ±a
- Nombre de la base de datos

**CompaÃ±ero con PostgreSQL:**
- Host/IP de la base de datos
- Puerto (usualmente 5432)
- Usuario y contraseÃ±a
- Nombre de la base de datos

**CompaÃ±ero con Cassandra:**
- Host/IP de la base de datos
- Puerto (usualmente 9042)
- Keyspace

---

## âš™ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Clonar el Repositorio

```bash
git clone <url-del-repositorio>
cd proyecto_parcial
```

### 2. Estructura de Archivos

```
proyecto_parcial/
â”œâ”€â”€ docker-compose.yml              # Para desarrollo local
â”œâ”€â”€ docker-compose.production.yml   # Para producciÃ³n
â”œâ”€â”€ .env.example                    # Variables de entorno para local
â”œâ”€â”€ .env.production.example         # Variables de entorno para producciÃ³n
â”œâ”€â”€ orchestrator.py                 # Orquestador de servicios
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ data_science_api/          # API AnalÃ­tica
â”‚   â”‚   â”œâ”€â”€ main.py                # Endpoints FastAPI
â”‚   â”‚   â”œâ”€â”€ s3_data_manager.py     # Gestor de datos S3
â”‚   â”‚   â”œâ”€â”€ mysql_s3_analytics.py  # Analytics MySQL
â”‚   â”‚   â”œâ”€â”€ postgresql_s3_analytics.py
â”‚   â”‚   â”œâ”€â”€ cassandra_s3_analytics.py
â”‚   â”‚   â”œâ”€â”€ cross_microservice_analytics.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ ingesta/                   # Servicio de Ingesta
â”‚       â”œâ”€â”€ ingest_data.py         # Script de ingesta
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â””â”€â”€ Dockerfile
â”œâ”€â”€ load_balancer/
â”‚   â””â”€â”€ nginx.conf                 # ConfiguraciÃ³n Nginx
â””â”€â”€ README.md
```

---

## ğŸ–¥ï¸ Modo Desarrollo Local

Este modo levanta TODAS las bases de datos localmente para pruebas.

### Paso 1: Configurar Variables de Entorno

```bash
cp .env.example .env
```

Edita el archivo `.env`:

```env
# AWS Configuration
AWS_ACCESS_KEY_ID=tu_access_key_aqui
AWS_SECRET_ACCESS_KEY=tu_secret_key_aqui
AWS_SESSION_TOKEN=tu_session_token_aqui  # Solo si usas AWS Academy
AWS_DEFAULT_REGION=us-east-1

# S3 Configuration
S3_BUCKET=tu-bucket-primac-analytics

# MySQL Configuration (Local)
MYSQL_HOST=mysql
MYSQL_PORT=3306
MYSQL_DATABASE=primac
MYSQL_USER=admin
MYSQL_PASSWORD=admin
MYSQL_ROOT_PASSWORD=root

# PostgreSQL Configuration (Local)
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=primac_postgres
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres

# Cassandra Configuration (Local)
CASSANDRA_HOST=cassandra
CASSANDRA_PORT=9042
CASSANDRA_KEYSPACE=primac_keyspace

# Environment
ENVIRONMENT=local
```

### Paso 2: Crear Bucket S3

```bash
# Crear bucket en AWS
aws s3 mb s3://tu-bucket-primac-analytics --region us-east-1
```

### Paso 3: Levantar los Servicios

```bash
# Construir y levantar todos los contenedores
docker compose up --build

# O en modo detached (background)
docker compose up --build -d
```

Esto levantarÃ¡:
- âœ… MySQL (puerto 3307)
- âœ… PostgreSQL (puerto 5432)
- âœ… Cassandra (puerto 9042)
- âœ… Servicio de Ingesta (ejecuta una vez)
- âœ… API AnalÃ­tica (puerto 8000)
- âœ… Balanceador de carga (puerto 80)

### Paso 4: Verificar Servicios

```bash
# Ver estado de contenedores
docker compose ps

# Ver logs
docker compose logs -f

# Ver logs de un servicio especÃ­fico
docker compose logs -f analytics_api
```

### Paso 5: Acceder a la API

Abre tu navegador en:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **A travÃ©s del balanceador**: http://localhost/docs

### Paso 6: Probar Endpoints

```bash
# Health check
curl http://localhost:8000/health

# EstadÃ­sticas de usuarios MySQL
curl http://localhost:8000/mysql/analytics/users

# AnÃ¡lisis de productos PostgreSQL
curl http://localhost:8000/postgresql/analytics/products

# AnÃ¡lisis de reclamos Cassandra
curl http://localhost:8000/cassandra/analytics/claims
```

### Detener Servicios Locales

```bash
# Detener contenedores
docker compose down

# Detener y eliminar volÃºmenes (limpieza completa)
docker compose down -v
```

---

## ğŸš€ Modo ProducciÃ³n

Este modo se conecta a las bases de datos remotas de tus compaÃ±eros.

### Arquitectura de ProducciÃ³n

```
VM CompaÃ±ero A â†’ MySQL BD
VM CompaÃ±ero B â†’ PostgreSQL BD
VM CompaÃ±ero C â†’ Cassandra BD
                    â†“
         TU VM 1 â† Ingesta â†’ S3 + Glue
         TU VM 2 â† API AnalÃ­tica
                    â†“
         Application Load Balancer (AWS)
```

### Paso 1: Recopilar InformaciÃ³n de CompaÃ±eros

Crea un documento con esta informaciÃ³n:

```
=== MICROSERVICIO MYSQL ===
Host: _________________________________
Puerto: _______________________________
Usuario: ______________________________
Password: _____________________________
Database: _____________________________

=== MICROSERVICIO POSTGRESQL ===
Host: _________________________________
Puerto: _______________________________
Usuario: ______________________________
Password: _____________________________
Database: _____________________________

=== MICROSERVICIO CASSANDRA ===
Host: _________________________________
Puerto: _______________________________
Keyspace: _____________________________
```

### Paso 2: Configurar Security Groups

**IMPORTANTE**: Tus compaÃ±eros deben permitir conexiones desde tu EC2.

Cada compaÃ±ero debe agregar en sus Security Groups:

```
MySQL:
Tipo: MySQL/Aurora
Puerto: 3306
Origen: <IP_DE_TU_EC2>/32

PostgreSQL:
Tipo: PostgreSQL
Puerto: 5432
Origen: <IP_DE_TU_EC2>/32

Cassandra:
Tipo: Custom TCP
Puerto: 9042
Origen: <IP_DE_TU_EC2>/32
```

### Paso 3: Configurar Variables de Entorno

```bash
cp .env.production.example .env.production
nano .env.production
```

Completa con los datos reales:

```env
# AWS Configuration (TU CUENTA)
AWS_ACCESS_KEY_ID=tu_access_key
AWS_SECRET_ACCESS_KEY=tu_secret_key
AWS_SESSION_TOKEN=tu_session_token
AWS_DEFAULT_REGION=us-east-1

# S3 Configuration (TU BUCKET)
S3_BUCKET=tu-bucket-primac-analytics

# MySQL REMOTO (Datos del CompaÃ±ero A)
MYSQL_HOST_REMOTE=ec2-xx-xxx-xxx-xx.compute-1.amazonaws.com
MYSQL_PORT_REMOTE=3306
MYSQL_USER_REMOTE=usuario_companero
MYSQL_PASSWORD_REMOTE=password_companero
MYSQL_DATABASE_REMOTE=database_companero

# PostgreSQL REMOTO (Datos del CompaÃ±ero B)
POSTGRES_HOST_REMOTE=ec2-yy-yyy-yyy-yy.compute-1.amazonaws.com
POSTGRES_PORT_REMOTE=5432
POSTGRES_USER_REMOTE=usuario_companero
POSTGRES_PASSWORD_REMOTE=password_companero
POSTGRES_DB_REMOTE=database_companero

# Cassandra REMOTO (Datos del CompaÃ±ero C)
CASSANDRA_HOST_REMOTE=ec2-zz-zzz-zzz-zz.compute-1.amazonaws.com
CASSANDRA_PORT_REMOTE=9042
CASSANDRA_KEYSPACE_REMOTE=keyspace_companero

# Environment
ENVIRONMENT=production
```

### Paso 4: Crear y Configurar EC2

#### 4.1. Crear Instancia EC2

En AWS Console:
1. Launch Instance
2. **AMI**: Ubuntu Server 22.04 LTS
3. **Instance type**: t2.medium (mÃ­nimo)
4. **Security Group**: Permitir puertos 22, 80, 8000
5. **Storage**: 20 GB mÃ­nimo

#### 4.2. Conectar a la EC2

```bash
ssh -i tu-key.pem ubuntu@tu-ec2-public-ip
```

#### 4.3. Instalar Docker y Docker Compose

```bash
# Actualizar sistema
sudo apt update && sudo apt upgrade -y

# Instalar Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker ubuntu

# Instalar Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Salir y volver a conectar para aplicar cambios
exit
ssh -i tu-key.pem ubuntu@tu-ec2-public-ip
```

#### 4.4. Verificar InstalaciÃ³n

```bash
docker --version
docker-compose --version
```

### Paso 5: Desplegar el Proyecto

```bash
# Clonar repositorio
git clone <url-repositorio>
cd proyecto_parcial

# Copiar y configurar variables de entorno
cp .env.production.example .env.production
nano .env.production  # Editar con datos reales

# Levantar servicios en producciÃ³n
docker-compose -f docker-compose.production.yml up --build -d
```

### Paso 6: Ejecutar Ingesta Inicial

```bash
# Ejecutar proceso de ingesta (solo una vez)
docker-compose -f docker-compose.production.yml run --rm ingesta

# Monitorear logs
docker-compose -f docker-compose.production.yml logs -f ingesta
```

La ingesta harÃ¡:
1. âœ… Conectarse a las 3 bases de datos remotas
2. âœ… Extraer el 100% de los registros
3. âœ… Convertir a CSV
4. âœ… Subir a S3
5. âœ… Crear catÃ¡logo en AWS Glue (`primac_analytics_db`)

### Paso 7: Verificar Despliegue

#### 7.1. Verificar Contenedores

```bash
docker-compose -f docker-compose.production.yml ps
```

DeberÃ­as ver:
- `analytics_api_production` (running)
- `nginx_lb_production` (running)

#### 7.2. Verificar S3

```bash
aws s3 ls s3://tu-bucket-primac-analytics/ --recursive
```

DeberÃ­as ver archivos como:
```
mysql/users/users.csv
mysql/clients/clients.csv
postgres/products/products.csv
postgres/policies/policies.csv
cassandra/reclamos/reclamos.csv
cassandra/pagos/pagos.csv
```

#### 7.3. Verificar AWS Glue

En AWS Console â†’ Glue â†’ Databases:
- Database: `primac_analytics_db`
- Tables: `mysql_users`, `postgresql_products`, `cassandra_reclamos`, etc.

#### 7.4. Probar API

```bash
# Health check
curl http://tu-ec2-public-ip:8000/health

# Swagger UI
http://tu-ec2-public-ip:8000/docs
```

### Paso 8: Configurar 2da VM y Load Balancer (Opcional)

Para producciÃ³n real con alta disponibilidad:

#### 8.1. Repetir pasos 4-7 en una segunda EC2

#### 8.2. Crear Application Load Balancer

En AWS Console:
1. EC2 â†’ Load Balancers â†’ Create Application Load Balancer
2. **Listeners**: HTTP (80), HTTPS (443)
3. **Target Group**:
   - Protocol: HTTP
   - Port: 8000
   - Health check path: `/health`
4. **Targets**: Agregar ambas EC2
5. Obtener DNS del Load Balancer

Acceder vÃ­a: `http://tu-load-balancer-dns.amazonaws.com/docs`

### Comandos Ãštiles en ProducciÃ³n

```bash
# Ver logs
docker-compose -f docker-compose.production.yml logs -f

# Reiniciar API
docker-compose -f docker-compose.production.yml restart analytics_api

# Detener todo
docker-compose -f docker-compose.production.yml down

# Ver uso de recursos
docker stats

# Limpiar espacio
docker system prune -a
```

---

## ğŸ“¡ Endpoints de la API

Una vez desplegada, la API expone los siguientes endpoints:

### ğŸ¥ Health Checks

#### `GET /`
**InformaciÃ³n general de la API**

```bash
curl http://localhost:8000/
```

Respuesta:
```json
{
  "message": "API Analytics - Primac S3",
  "version": "2.0.0",
  "status": "OK",
  "data_source": "S3 Bucket",
  "available_databases": ["MySQL", "PostgreSQL", "Cassandra"],
  "endpoints": {
    "mysql": 2,
    "postgresql": 2,
    "cassandra": 2,
    "cross_microservice": 3
  }
}
```

#### `GET /health`
**Estado del servicio y disponibilidad de datos en S3**

```bash
curl http://localhost:8000/health
```

Respuesta:
```json
{
  "status": "OK",
  "timestamp": "2025-10-22T10:30:00",
  "data_availability": {
    "mysql": {
      "users": true,
      "clients": true,
      "agents": true
    },
    "postgresql": {
      "products": true,
      "policies": true
    },
    "cassandra": {
      "reclamos": true,
      "pagos": true
    }
  },
  "bucket_summary": {
    "total_objects": 12,
    "total_size_mb": 45.67
  }
}
```

### ğŸ—„ï¸ MySQL Analytics

#### `GET /mysql/analytics/users`
**EstadÃ­sticas generales de usuarios**

Analiza datos de la tabla `users` de MySQL.

```bash
curl http://localhost:8000/mysql/analytics/users
```

Retorna:
- Total de usuarios registrados
- DistribuciÃ³n por estado/regiÃ³n
- EstadÃ­sticas demogrÃ¡ficas
- AnÃ¡lisis temporal de registros

#### `GET /mysql/analytics/growth-by-state?months=12`
**Crecimiento de usuarios por estado**

Analiza evoluciÃ³n temporal del registro de usuarios.

```bash
curl "http://localhost:8000/mysql/analytics/growth-by-state?months=12"
```

ParÃ¡metros:
- `months` (opcional): Ventana temporal en meses (1-36), default: 12

Retorna:
- Serie temporal de registros por estado
- Tasa de crecimiento por regiÃ³n
- Estados con mayor crecimiento

### ğŸ—„ï¸ PostgreSQL Analytics

#### `GET /postgresql/analytics/products`
**AnÃ¡lisis completo de productos y pÃ³lizas**

Analiza datos de las tablas `products` y `policies` de PostgreSQL.

```bash
curl http://localhost:8000/postgresql/analytics/products
```

Retorna:
- Total de productos disponibles
- DistribuciÃ³n de pÃ³lizas por tipo
- EstadÃ­sticas de cobertura
- Productos mÃ¡s vendidos

#### `GET /postgresql/analytics/product-profitability`
**AnÃ¡lisis de rentabilidad por producto**

```bash
curl http://localhost:8000/postgresql/analytics/product-profitability
```

Retorna:
- Ingresos por producto
- NÃºmero de pÃ³lizas activas
- Valor promedio de primas
- ROI y mÃ©tricas de rentabilidad

### ğŸ—„ï¸ Cassandra Analytics

#### `GET /cassandra/analytics/claims`
**AnÃ¡lisis de reclamos y siniestros**

Analiza datos de la tabla `reclamos` de Cassandra.

```bash
curl http://localhost:8000/cassandra/analytics/claims
```

Retorna:
- Total de reclamos registrados
- DistribuciÃ³n por tipo de reclamo
- Estados (pendiente, aprobado, rechazado)
- Montos promedio de reclamos

#### `GET /cassandra/analytics/claims-payments-correlation`
**CorrelaciÃ³n entre reclamos y pagos**

```bash
curl http://localhost:8000/cassandra/analytics/claims-payments-correlation
```

Retorna:
- Tasa de aprobaciÃ³n de reclamos
- Tiempo promedio entre reclamo y pago
- Monto promedio pagado vs reclamado
- Eficiencia del proceso

### ğŸ”„ Cross-Microservice Analytics

#### `GET /cross/analytics/customer-policy-profile`
**Perfil de clientes y sus pÃ³lizas** (MySQL + PostgreSQL)

Combina datos de clientes (MySQL) con sus pÃ³lizas (PostgreSQL).

```bash
curl http://localhost:8000/cross/analytics/customer-policy-profile
```

Retorna:
- Perfil demogrÃ¡fico de clientes
- PÃ³lizas activas por cliente
- Valor total de cobertura
- SegmentaciÃ³n de clientes

#### `GET /cross/analytics/agent-performance`
**Rendimiento de agentes de ventas** (MySQL + PostgreSQL)

Combina datos de agentes (MySQL) con pÃ³lizas vendidas (PostgreSQL).

```bash
curl http://localhost:8000/cross/analytics/agent-performance
```

Retorna:
- PÃ³lizas vendidas por agente
- Valor total de primas generadas
- Ranking de agentes
- Tasa de conversiÃ³n

#### `GET /cross/analytics/claims-vs-policies`
**AnÃ¡lisis de siniestralidad** (PostgreSQL + Cassandra)

Combina pÃ³lizas (PostgreSQL) con reclamos (Cassandra).

```bash
curl http://localhost:8000/cross/analytics/claims-vs-policies
```

Retorna:
- Ratio de siniestralidad por producto
- Frecuencia de reclamos
- Loss ratio (pagos/primas)
- Productos con mayor/menor siniestralidad

---

## ğŸ“‚ Estructura del Proyecto

```
proyecto_parcial/
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ data_science_api/              # API de AnÃ¡lisis
â”‚   â”‚   â”œâ”€â”€ main.py                    # Endpoints FastAPI con Swagger
â”‚   â”‚   â”œâ”€â”€ s3_data_manager.py         # Gestor de datos desde S3
â”‚   â”‚   â”œâ”€â”€ mysql_s3_analytics.py      # LÃ³gica de analytics MySQL
â”‚   â”‚   â”œâ”€â”€ postgresql_s3_analytics.py # LÃ³gica de analytics PostgreSQL
â”‚   â”‚   â”œâ”€â”€ cassandra_s3_analytics.py  # LÃ³gica de analytics Cassandra
â”‚   â”‚   â”œâ”€â”€ cross_microservice_analytics.py  # Analytics cruzados
â”‚   â”‚   â”œâ”€â”€ requirements.txt           # Dependencias Python
â”‚   â”‚   â””â”€â”€ Dockerfile                 # Container de la API
â”‚   â”‚
â”‚   â””â”€â”€ ingesta/                       # Servicio de Ingesta
â”‚       â”œâ”€â”€ ingest_data.py             # Script de ingesta a S3 + Glue
â”‚       â”œâ”€â”€ requirements.txt           # Dependencias Python
â”‚       â””â”€â”€ Dockerfile                 # Container de ingesta
â”‚
â”œâ”€â”€ load_balancer/
â”‚   â””â”€â”€ nginx.conf                     # ConfiguraciÃ³n del Load Balancer
â”‚
â”œâ”€â”€ docker-compose.yml                 # OrquestaciÃ³n para desarrollo local
â”œâ”€â”€ docker-compose.production.yml      # OrquestaciÃ³n para producciÃ³n
â”œâ”€â”€ orchestrator.py                    # Script orquestador de servicios
â”‚
â”œâ”€â”€ .env.example                       # Template variables locales
â”œâ”€â”€ .env.production.example            # Template variables producciÃ³n
â””â”€â”€ README.md                          # Este archivo (guÃ­a completa)
```

### DescripciÃ³n de Componentes Clave

**`services/data_science_api/main.py`**
- Define todos los endpoints REST
- DocumentaciÃ³n Swagger/OpenAPI
- Manejo de errores y validaciones

**`services/ingesta/ingest_data.py`**
- ConexiÃ³n a las 3 bases de datos
- ExtracciÃ³n completa de datos (100%)
- Upload a S3
- CreaciÃ³n de catÃ¡logo en AWS Glue

**`docker-compose.yml`**
- Levanta bases de datos locales (MySQL, PostgreSQL, Cassandra)
- Para desarrollo y pruebas locales

**`docker-compose.production.yml`**
- No levanta bases de datos
- Se conecta a bases remotas de compaÃ±eros
- Para despliegue en producciÃ³n

---

## ğŸ”§ Troubleshooting

### Problema: No puedo conectarme a las bases de datos remotas

**SÃ­ntomas:**
```
Error: Can't connect to MySQL server
Error: Connection refused PostgreSQL
```

**Soluciones:**

1. **Verificar Security Groups**
   - Los Security Groups de tus compaÃ±eros deben permitir tu IP en los puertos correctos
   - Verificar con: `telnet host-remoto puerto`

2. **Verificar credenciales**
   - Confirmar usuario y password con tus compaÃ±eros
   - Verificar que el usuario tenga permisos de lectura

3. **Probar conexiÃ³n manualmente**
   ```bash
   # MySQL
   mysql -h host-remoto -u usuario -p

   # PostgreSQL
   psql -h host-remoto -U usuario -d database

   # Cassandra
   cqlsh host-remoto 9042
   ```

### Problema: Error de permisos en AWS S3/Glue

**SÃ­ntomas:**
```
AccessDenied: User is not authorized to perform: s3:PutObject
AccessDenied: User is not authorized to perform: glue:CreateTable
```

**Soluciones:**

1. **Verificar permisos IAM**
   - Tu usuario debe tener permisos `s3:PutObject`, `s3:GetObject`
   - Tu usuario debe tener permisos `glue:CreateDatabase`, `glue:CreateTable`

2. **Si usas AWS Academy**
   - El `AWS_SESSION_TOKEN` expira cada 4 horas
   - Regenerar credenciales desde AWS Academy
   - Actualizar `.env` o `.env.production`

3. **Verificar bucket existe**
   ```bash
   aws s3 ls s3://tu-bucket-primac-analytics/
   ```

### Problema: La ingesta tarda mucho o falla

**SÃ­ntomas:**
```
Timeout waiting for connection
Process killed (OOM)
```

**Soluciones:**

1. **Verificar volumen de datos**
   - Es normal que tarde varios minutos con 20,000+ registros
   - Monitorear con: `docker logs -f ingesta`

2. **Aumentar recursos de Docker**
   - Docker Desktop â†’ Settings â†’ Resources
   - Aumentar RAM a 4GB mÃ­nimo

3. **Verificar timeouts de red**
   - Bases de datos remotas pueden tener timeouts cortos
   - Contactar a compaÃ±eros para aumentar `wait_timeout` (MySQL) o `statement_timeout` (PostgreSQL)

### Problema: La API no responde

**SÃ­ntomas:**
```
curl: (7) Failed to connect to localhost port 8000
```

**Soluciones:**

1. **Verificar contenedor corriendo**
   ```bash
   docker ps | grep analytics_api
   ```

2. **Ver logs del contenedor**
   ```bash
   docker logs analytics_api
   ```

3. **Verificar puerto no ocupado**
   ```bash
   sudo lsof -i :8000
   ```

4. **Reiniciar contenedor**
   ```bash
   docker-compose restart analytics_api
   ```

### Problema: Swagger UI no muestra la documentaciÃ³n

**SÃ­ntomas:**
- PÃ¡gina en blanco en `/docs`
- Error 404

**Soluciones:**

1. **Verificar que la API estÃ© corriendo**
   ```bash
   curl http://localhost:8000/
   ```

2. **Limpiar cache del navegador**
   - Ctrl + Shift + R (forzar recarga)

3. **Probar con `/redoc` alternativo**
   ```
   http://localhost:8000/redoc
   ```

### Problema: Datos no aparecen en S3

**SÃ­ntomas:**
- Bucket vacÃ­o despuÃ©s de ingesta
- Error al listar archivos

**Soluciones:**

1. **Verificar logs de ingesta**
   ```bash
   docker logs ingesta
   ```

2. **Verificar bucket correcto**
   ```bash
   aws s3 ls  # Lista todos tus buckets
   ```

3. **Verificar permisos de escritura**
   ```bash
   aws s3 cp test.txt s3://tu-bucket-primac-analytics/test.txt
   ```

### Problema: AWS Glue Catalog no se crea

**SÃ­ntomas:**
- Database `primac_analytics_db` no aparece en Glue Console
- Tablas no visibles

**Soluciones:**

1. **Verificar regiÃ³n correcta**
   - AWS Console debe estar en la misma regiÃ³n que `AWS_DEFAULT_REGION` en `.env`

2. **Verificar permisos Glue**
   ```bash
   aws glue get-databases
   ```

3. **Ejecutar ingesta nuevamente**
   ```bash
   docker-compose -f docker-compose.production.yml run --rm ingesta
   ```

### Problema: Out of Memory en EC2

**SÃ­ntomas:**
```
Killed
Process terminated (137)
```

**Soluciones:**

1. **Verificar recursos de EC2**
   ```bash
   free -h
   htop
   ```

2. **Usar instancia mÃ¡s grande**
   - MÃ­nimo recomendado: t2.medium (4GB RAM)
   - Para producciÃ³n: t2.large o t3.large

3. **Agregar swap space**
   ```bash
   sudo fallocate -l 2G /swapfile
   sudo chmod 600 /swapfile
   sudo mkswap /swapfile
   sudo swapon /swapfile
   ```

---

## ğŸ“ Soporte y Contacto

### Recursos Adicionales

- **DocumentaciÃ³n FastAPI**: https://fastapi.tiangolo.com/
- **DocumentaciÃ³n Boto3**: https://boto3.amazonaws.com/v1/documentation/api/latest/index.html
- **DocumentaciÃ³n AWS Glue**: https://docs.aws.amazon.com/glue/
- **Docker Compose**: https://docs.docker.com/compose/

### Checklist de Despliegue

#### Antes del Despliegue:
- [ ] Recopilar credenciales de bases de datos de compaÃ±eros
- [ ] Configurar Security Groups para permitir conexiones
- [ ] Crear bucket S3 en AWS
- [ ] Verificar permisos IAM (S3 + Glue)
- [ ] Probar conexiones a bases de datos remotas

#### Durante el Despliegue:
- [ ] Crear EC2 instance con puertos 22, 80, 8000 abiertos
- [ ] Instalar Docker y Docker Compose en EC2
- [ ] Clonar repositorio
- [ ] Configurar `.env.production` con datos reales
- [ ] Ejecutar `docker-compose.production.yml`
- [ ] Ejecutar ingesta de datos

#### DespuÃ©s del Despliegue:
- [ ] Verificar datos en S3
- [ ] Verificar catÃ¡logo en AWS Glue
- [ ] Probar todos los endpoints de la API
- [ ] Verificar Swagger UI accesible
- [ ] Compartir URL de tu API con el equipo

---

## ğŸ“„ Licencia

Este proyecto es parte de un trabajo acadÃ©mico para el curso de Cloud Computing - UTEC.

---

## ğŸ™ Agradecimientos

- Equipo de desarrollo Primac
- Profesores del curso Cloud Computing
- CompaÃ±eros de equipo por sus microservicios

---

**VersiÃ³n**: 2.0.0
**Ãšltima actualizaciÃ³n**: Octubre 2025
**Autor**: Equipo AnalÃ­tica Primac
